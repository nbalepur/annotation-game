<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Human Preferences (IRB)</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 20px;
        }
        h1, h3 {
            color: #2c3e50;
        }
        p {
            margin-bottom: 1em;
        }
        .section {
            margin-bottom: 2em;
        }
    </style>
</head>
<body>

    <h3>Project Title : Aligning Machine Learning Models to Personalized and Downstream User Needs (IRB)</h3>
    <br />

    <div class="section">
        <h3>Purpose of the Study</h3>
        <p>This research is being conducted by Jordan Boyd-Graber at the University of Maryland, College Park. We are inviting you to participate in this research project because you are interested in and often perform writing, coding, information retrieval, and decision-making tasks. The purpose of this research project is to use machine learning-based advice and instructions to make performing these tasks more efficient and accurate</p>
    </div>

    <div class="section">
        <h3>Procedures</h3>
        <p>You will participate in tasks designed to see how model-generated instructions affect your ability to complete tasks accurately and efficiently. The tasks will fall into four categories: coding, writing, decision-making, and information seeking (e.g., finding documents or answering questions). You’ll begin by choosing one of these categories, then receive specific tasks based on your choice. For example, in the coding category, you might be asked to write a function, or in decision-making, to classify an email as spam. These tasks come from existing datasets in natural language processing and machine learning.</p>

        <p>You’ll be placed in one of two groups: 1) completing tasks on your own, or 2) completing tasks with model-generated instructions. This allows us to measure how the model's advice affects your performance in terms of accuracy and speed. Each task will have a one-minute time limit. We’ll measure how accurately and quickly you complete each one using automated metrics, such as test case completion for coding tasks or grammar and coherence for writing. You can also provide preferences (e.g., "I prefer code with no comments") to personalize the model’s instructions. This helps us see how personalized advice impacts your performance.</p>
        
        <p>Some sessions will include competitive tasks where you’ll compete against others. These will follow the same procedure (with or without model-generated instructions), but we’ll also measure your performance against others. </p>
        
        <p>Top performers, measured through task completion rate (accuracy) and efficiency (time taken) may earn rewards in both the competition and non-competition based user studies, explained below. </p>
        
        <p>Each session will last about 60 minutes, with one task per minute. Sessions will run from October 2024 to October 2025, and you may be invited to join additional sessions, though this is optional.
        We’ll collect data on your task time, accuracy, and any preferences you provide. Your data will be linked to an anonymized user ID, with only your email stored for reward distribution. </p>
    </div>

    <div class="section">
        <h3>Potential Risks and Discomforts</h3>
        <p>Potential Risks and
            Discomforts
                The only known risk to participants of this study is in confidentiality of study participation. This risk will be mitigated through the procedures described in the section titled “Confidentiality” below.
            </p>
    </div>

    <div class="section">
        <h3>Potential Benefits</h3>
        <p>There are no direct benefits. However, this study aims to use techniques in machine learning and natural language processing to improve learning and the ability to complete tasks more efficiently. Participants in this study may therefore benefit from being able to learn how to better tackle tasks they are interested in improving in. Our user study could also help participants prepare for specific competitions, such as writing and coding contests, through model-generated instructions and personalized guidance for task completion.         </p>
    </div>

    <div class="section">
        <h3>Confidentiality</h3>
        <p>Data collected in this study will be securely stored in a database hosted on password protected webservers and cloud-based file storage. Only researchers will have access to users’ emails and no other identifying information will be collected in the app. After the end of the experiment, data will be anonymized and released publicly. The user’s email will be kept in a separate table and linked to a username and user id. These user ids and usernames are used throughout the experiment to assign different models/instructions and for statistical leaderboards, but the collected usernames and emails and links to public statistics pages will be destroyed after the completion of this study. To maintain linkage in study data, a new randomized user id will be generated in replacement of the identification keys in use during the study.</p>

            <p>If we write a report or article about this research project, your identity will be protected to the maximum extent possible. Your information may be shared with representatives of the University of Maryland, College Park or governmental authorities if you or someone else is in danger or if we are required to do so by law.</p>
            
            <p>During the course of the study, the collected data will only be accessible to PI Jordan Boyd-Graber and Co-PIs Nishant Balepur, Shi Feng, and Matthew Shu. Your identifiable information (email address) will be deleted at the end of the study.</p>
    </div>

    <div class="section">
        <h3>Compensation</h3>
        <p>For each user study, we will pay recruited participants a fair, hourly wage (at a minimum $15/hour MD minimum wage). Users who perform exceptionally well in our competition and non-competition-based user studies can earn up to an extra $50 in additional rewards. We expect to distribute these extra rewards to a maximum of 10 participants. Participants will be eligible for extra compensation over the course of each planned time span for the user studies and will be distributed at most on a monthly basis. Participants will receive the base $15/hour rewards after we verify that they completed the instructions for our user study (ETA 1 week maximum), and the extra rewards within 1.5 months maximum of participating. The extra rewards will take slightly longer to distribute, as we must calculate who were the highest performers at the end of the user study duration (expected to be 1 month).</p>
    </div>

    <div class="section">
        <h3>Right to Withdraw and Questions</h3>
        <p>Your participation in this research is completely voluntary. You may choose not to take part at all. If you decide to participate in this research, you may stop participating at any time. If you decide not to participate in this study or if you stop participating at any time, you will not be penalized or lose any benefits to which you otherwise qualify.</p>
        <p>If you decide to stop taking part in the study, if you have questions, concerns, or complaints, or if you need to report an injury related to the research, please contact the investigator:</p>
        <p>Jordan Boyd-Graber<br>
            4146 Iribe University of Maryland<br>
            College Park, Maryland, 20742<br>
            E-mail: <a href="mailto:jbg@umiacs.umd.edu">jbg@umiacs.umd.edu</a><br>
            Telephone: (301) 405-6766</p>
    </div>

    <div class="section">
        <h3>Participant Rights</h3>
        <p>If you have questions about your rights as a research participant or wish to report a research-related injury, please contact:</p>
        <p>University of Maryland College Park<br>
            Institutional Review Board Office<br>
            1204 Marie Mount Hall<br>
            College Park, Maryland, 20742<br>
            E-mail: <a href="mailto:irb@umd.edu">irb@umd.edu</a><br>
            Telephone: 301-405-0678</p>
        <p>For more information regarding participant rights, please visit:<br>
            <a href="https://research.umd.edu/research-resources/research-compliance/institutional-review-board-irb/research-participants">Participant Rights Information</a></p>
        <p>This research has been reviewed according to the University of Maryland, College Park IRB procedures for research involving human subjects.</p>
    </div>

    <div class="section">
        <h3>Statement of Consent</h3>
        <p>Statement of Consent
            By clicking “I agree”, you indicate that you are at least 18 years of age; you have read this consent form or have had it read to you; your questions have been answered to your satisfaction and you voluntarily agree to participate in this research study. We advise you to download a copy of this consent form for your own records.</p>
    </div>

</body>
<footer>Approved as IRBNet Package: 2237749-1</footer>
</html>
